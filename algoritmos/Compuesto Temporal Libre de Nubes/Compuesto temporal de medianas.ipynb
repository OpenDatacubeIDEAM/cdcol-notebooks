{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compuesto temporal de medianas workflow and notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators import CompressFileSensor\n",
    "from cdcol_utils import other_utils\n",
    "import airflow\n",
    "from airflow.models import DAG\n",
    "from airflow.operators import CDColQueryOperator, CDColFromFileOperator, CDColReduceOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from cdcol_utils import dag_utils, queue_utils, other_utils\n",
    "from airflow.utils.trigger_rule import TriggerRule\n",
    "\n",
    "from datetime import timedelta\n",
    "from pprint import pprint\n",
    "\n",
    "_params = {'minValid': 1, 'normalized': False, 'lat': (2, 3), 'lon': (-74, -73), 'products': [{'name': 'LS7_ETM_LEDAPS', 'bands': ['swir1', 'nir', 'red', 'green', 'blue', 'swir2', 'pixel_qa']}, {'name': 'LS8_OLI_LASRC', 'bands': ['swir1', 'nir', 'red', 'green', 'blue', 'swir2', 'pixel_qa']}], 'time_ranges': [('2020-01-01', '2020-06-30')], 'execID': 'exec_6849', 'elimina_resultados_anteriores': True, 'genera_mosaico': True, 'owner': 'API-REST'}\n",
    "\n",
    "\n",
    "_steps = {\n",
    "    'mascara': {\n",
    "        'algorithm': \"mascara-landsat\",\n",
    "        'version': '1.0',\n",
    "        'queue': queue_utils.assign_queue(\n",
    "            input_type='multi_temporal',\n",
    "            time_range=_params['time_ranges'][0]\n",
    "        ),\n",
    "        'params': {},\n",
    "    },\n",
    "    'reduccion': {\n",
    "        #'algorithm': \"joiner-reduce\",\n",
    "        'algorithm': \"joiner\",\n",
    "        'version': '1.0',\n",
    "        'queue':'airflow_xlarge',\n",
    "        # 'queue': queue_utils.assign_queue(\n",
    "        #     input_type='multi_temporal_unidad', \n",
    "        #     time_range=_params['time_ranges'][0],\n",
    "        #     unidades=len(_params['products'])\n",
    "        # ),\n",
    "        'params': {},\n",
    "        'del_prev_result': _params['elimina_resultados_anteriores'],\n",
    "    },\n",
    "    'medianas': {\n",
    "        'algorithm': \"compuesto-temporal-medianas-wf\",\n",
    "        'version': '1.0',\n",
    "        'queue': queue_utils.assign_queue(\n",
    "            input_type='multi_temporal_unidad',\n",
    "            time_range=_params['time_ranges'][0],\n",
    "            unidades=len(_params['products'])\n",
    "        ),\n",
    "        'params': {\n",
    "            'normalized':_params['normalized'],\n",
    "            'minValid': _params['minValid'],\n",
    "        },\n",
    "        'del_prev_result': _params['elimina_resultados_anteriores'],\n",
    "    },\n",
    "    'mosaico': {\n",
    "        'algorithm': \"joiner\",\n",
    "        'version': '1.0',\n",
    "        'queue': queue_utils.assign_queue(\n",
    "            input_type='multi_area',\n",
    "            lat=_params['lat'],\n",
    "            lon=_params['lon']),\n",
    "        'params': {},\n",
    "        'del_prev_result': _params['elimina_resultados_anteriores'],\n",
    "    }\n",
    "}\n",
    "\n",
    "args = {\n",
    "    'owner': _params['owner'],\n",
    "    'start_date': airflow.utils.dates.days_ago(2),\n",
    "    'execID': _params['execID'],\n",
    "    'product':_params['products'][0]\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    dag_id=args['execID'], default_args=args,\n",
    "    schedule_interval=None,\n",
    "    dagrun_timeout=timedelta(minutes=120)\n",
    ")\n",
    "\n",
    "mascara_0 = dag_utils.queryMapByTile(\n",
    "    lat=_params['lat'], \n",
    "    lon=_params['lon'],\n",
    "    time_ranges=_params['time_ranges'][0],\n",
    "    algorithm=_steps['mascara']['algorithm'],\n",
    "    version=_steps['mascara']['version'],\n",
    "    product=_params['products'][0],\n",
    "    params=_steps['mascara']['params'],\n",
    "    queue=_steps['mascara']['queue'],\n",
    "    dag=dag,\n",
    "    task_id=\"mascara_\" + _params['products'][0]['name']\n",
    ")\n",
    "\n",
    "if len(_params['products']) > 1:\n",
    "    mascara_1 = dag_utils.queryMapByTile(\n",
    "        lat=_params['lat'],\n",
    "        lon=_params['lon'],\n",
    "        time_ranges=_params['time_ranges'][0],\n",
    "        algorithm=_steps['mascara']['algorithm'],\n",
    "        version=_steps['mascara']['version'],\n",
    "        product=_params['products'][1],\n",
    "        params=_steps['mascara']['params'],\n",
    "        queue=_steps['mascara']['queue'],\n",
    "        dag=dag,\n",
    "        task_id=\"mascara_\" + _params['products'][1]['name']\n",
    "    )\n",
    "\n",
    "    reduccion = dag_utils.reduceByTile(\n",
    "        mascara_0 + mascara_1,\n",
    "        algorithm=_steps['reduccion']['algorithm'],\n",
    "        version=_steps['reduccion']['version'],\n",
    "        queue=_steps['reduccion']['queue'],\n",
    "        product=_params['products'][0],\n",
    "        dag=dag, task_id=\"joined\",\n",
    "        delete_partial_results=_steps['reduccion']['del_prev_result'],\n",
    "        params=_steps['reduccion']['params'], \n",
    "    )\n",
    "else:\n",
    "    reduccion = mascara_0\n",
    "\n",
    "medianas = dag_utils.IdentityMap(\n",
    "    reduccion,\n",
    "    product=_params['products'][0],\n",
    "    algorithm=_steps['medianas']['algorithm'],\n",
    "    version=_steps['medianas']['version'],\n",
    "    task_id=\"medianas\",\n",
    "    queue=_steps['medianas']['queue'], \n",
    "    dag=dag,\n",
    "    delete_partial_results=_steps['medianas']['del_prev_result'],\n",
    "    params=_steps['medianas']['params'], \n",
    "    to_tiff= not (_params['genera_mosaico'] and queue_utils.get_tiles(_params['lat'],_params['lon'])>1)\n",
    ")\n",
    "\n",
    "workflow = medianas\n",
    "\n",
    "if _params['genera_mosaico'] and queue_utils.get_tiles(_params['lat'],_params['lon'])>1:\n",
    "    mosaico = dag_utils.OneReduce(\n",
    "        workflow,\n",
    "        task_id=\"mosaic\",\n",
    "        algorithm=_steps['mosaico']['algorithm'],\n",
    "        version=_steps['mosaico']['version'],\n",
    "        queue=_steps['mosaico']['queue'],\n",
    "        delete_partial_results=_steps['mosaico']['del_prev_result'],\n",
    "        trigger_rule=TriggerRule.NONE_FAILED,\n",
    "        dag=dag,\n",
    "        to_tiff=True\n",
    "    )\n",
    "\n",
    "    workflow = mosaico\n",
    "\n",
    "workflow\n",
    "\n",
    "sensor_fin_ejecucion = CompressFileSensor(task_id='sensor_fin_ejecucion',poke_interval=60, soft_fail=True,mode='reschedule', queue='util', dag=dag) \n",
    "comprimir_resultados = PythonOperator(task_id='comprimir_resultados',provide_context=True,python_callable=other_utils.compress_results,queue='util',op_kwargs={'execID': args['execID']},dag=dag) \n",
    "sensor_fin_ejecucion >> comprimir_resultados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(product)\n",
    "print (\"Masking \" + product['name'])\n",
    "nodata=-9999\n",
    "validValues=set()\n",
    "if product['name']==\"LS7_ETM_LEDAPS\" or product['name'] == \"LS5_TM_LEDAPS\":\n",
    "    validValues=[66,68,130,132]\n",
    "elif product['name'] == \"LS8_OLI_LASRC\":\n",
    "    validValues=[322, 386, 834, 898, 1346, 324, 388, 836, 900, 1348]\n",
    "else:\n",
    "    raise Exception(\"Este algoritmo s√≥lo puede enmascarar LS7_ETM_LEDAPS, LS5_TM_LEDAPS o LS8_OLI_LASRC\")\n",
    "\n",
    "cloud_mask = np.isin(xarr0[\"pixel_qa\"].values, validValues)\n",
    "for band in product['bands']:\n",
    "    print(\"entra a enmascarar\")\n",
    "    xarr0[band].values = np.where(np.logical_and(xarr0.data_vars[band] != nodata, cloud_mask), xarr0.data_vars[band], -9999)\n",
    "output = xarr0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob, os,sys\n",
    "\n",
    "output=None\n",
    "xarrs=xarrs.values()\n",
    "for _xarr in xarrs:\n",
    "    if (output is None):\n",
    "        output = _xarr\n",
    "    else:\n",
    "        output=output.combine_first(_xarr)\n",
    "\n",
    "#output=xr.auto_combine(list(xarrs))\n",
    "#output=xr.open_mfdataset(\"/source_storage/results/compuesto_de_medianas/compuesto-temporal-medianas-wf_1.0/*.nc\")\n",
    "#output=xr.merge(list(xarrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# coding=utf8\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "print (\"Compuesto temporal de medianas para \" + product['name'])\n",
    "print(xarr0)\n",
    "nodata=-9999\n",
    "medians = {}\n",
    "time_axis = list(xarr0.coords.keys()).index('time')\n",
    "for band in product['bands']:\n",
    "    if band != 'pixel_qa':\n",
    "        datos = xarr0.data_vars[band].values\n",
    "        allNan = ~np.isnan(datos)\n",
    "\n",
    "        # Comentada por Aurelio (No soporta multi unidad)\n",
    "        #if normalized:\n",
    "        #    m=np.nanmean(datos.reshape((datos.shape[time_axis],-1)), axis=1)\n",
    "        #    st=np.nanstd(datos.reshape((datos.shape[time_axis],-1)), axis=1)\n",
    "        #    datos=np.true_divide((datos-m[:,np.newaxis,np.newaxis]), st[:,np.newaxis,np.newaxis])*np.nanmean(st)+np.nanmean(m)\n",
    "\n",
    "        if normalized:\n",
    "            m=np.nanmean(datos.reshape((datos.shape[time_axis],-1)), axis=1)\n",
    "            st=np.nanstd(datos.reshape((datos.shape[time_axis],-1)), axis=1)\n",
    "\n",
    "            # Expand m and st according with the data shape\n",
    "            # number of coords\n",
    "            coords_num = len(list(xarr0.coords.keys()))\n",
    "            l = [ x for x in range(coords_num) if x != time_axis]\n",
    "\n",
    "            m_new = m\n",
    "            st_new = st\n",
    "            for axis in l:\n",
    "                # If axis is 0  it is equivalent to x[np.newaxis,:]\n",
    "                # If axis is 1  it is equivalent to x[:,np.newaxis]\n",
    "                # And so on\n",
    "                m_new = np.expand_dims(m_new,axis=axis)\n",
    "                st_new = np.expand_dims(st_new,axis=axis)\n",
    "\n",
    "            print('Time axis',time_axis)\n",
    "            print('New axis',l)\n",
    "            print('m',m.shape)\n",
    "            print('st',st.shape)\n",
    "            print('st_new',st_new.shape)\n",
    "            print('m_new',m_new.shape)\n",
    "            datos=np.true_divide((datos-m_new), st_new)*np.nanmean(st)+np.nanmean(m)\n",
    "\n",
    "        medians[band] = np.nanmedian(datos, time_axis)\n",
    "        medians[band][np.sum(allNan, time_axis) < minValid] = -9999\n",
    "        del datos\n",
    "\n",
    "# > **Asignaci√≥n de coordenadas**\n",
    "ncoords=[]\n",
    "xdims =[]\n",
    "xcords={}\n",
    "for x in xarr0.coords:\n",
    "    if(x!='time'):\n",
    "        ncoords.append( ( x, xarr0.coords[x]) )\n",
    "        xdims.append(x)\n",
    "        xcords[x]=xarr0.coords[x]\n",
    "variables ={k: xr.DataArray(v, dims=xdims,coords=ncoords) for k, v in medians.items()}\n",
    "output=xr.Dataset(variables, attrs={'crs':xarr0.crs})\n",
    "for x in output.coords:\n",
    "    output.coords[x].attrs[\"units\"]=xarr0.coords[x].units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob, os,sys\n",
    "\n",
    "output=None\n",
    "xarrs=xarrs.values()\n",
    "for _xarr in xarrs:\n",
    "    if (output is None):\n",
    "        output = _xarr\n",
    "    else:\n",
    "        output=output.combine_first(_xarr)\n",
    "\n",
    "#output=xr.auto_combine(list(xarrs))\n",
    "#output=xr.open_mfdataset(\"/source_storage/results/compuesto_de_medianas/compuesto-temporal-medianas-wf_1.0/*.nc\")\n",
    "#output=xr.merge(list(xarrs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
